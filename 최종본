def reward_function(params):
    '''
    Example of rewarding the agent to follow center line
    '''
    
    # Read input parameters
    all_wheels_on_track = params["all_wheels_on_track"]
    speed = params["speed"]
    is_offtrack = params["is_offtrack"]
    
    reward = 0
    
    if 3 <= speed <= 3.5:
        reward = 1.5
    elif 2.5 <= speed < 3:
        reward = 1
    elif 2 <= speed < 2.5:
        reward = 0.5        
    elif 1.5 <= speed < 2:
        reward = 0.2        
    elif 1 <= speed < 1.5:
        reward = 0.05    
        
    if is_offtrack == False:
        reward += 4
    
    
    return float(reward)
# 탐색가능한 공간이 넓다 보니 위와 같은 보상으로는 쉽게 최적해로 탐색해가지 못함
# 개선 방안
# 1. 속도가 높아야만 하기 때문에 제한 속도를 높이고 높은 속도일 때의 reward를 높인다.
# 2. 좀 더 구체적인 보상함수를 통해 탐색 공간을 축소 시킨다. ex) process를 reward로 하여 최단 거리의 중요성 학습
# 3. 시간을 더 많이 사용하여 최적해를 찾을 수 있게 함.(그에 따른 entropy parameter 수정도 필요할 것으로 보임)
